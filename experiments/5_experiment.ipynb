{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ae3e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:44.094868Z",
     "start_time": "2022-01-10T00:00:41.508786Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d369c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:44.191083Z",
     "start_time": "2022-01-10T00:00:44.097401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4\n",
      "erythropoiesis\n",
      "      2\n",
      "    Proerythroblast\n",
      "    Erythroblast\n",
      " \n",
      "lymphoid\n",
      "      3\n",
      "    Immature Lymphocyte\n",
      "    Lymphocyte\n",
      "    Plasma Cell\n",
      " \n",
      "myeloid\n",
      "      2\n",
      "    myeloid_immature\n",
      "          4\n",
      "        Myeloblast\n",
      "        Metamyelocyte\n",
      "        Myelocyte\n",
      "        Promyelocyte\n",
      " \n",
      "    myeloid_mature\n",
      "          4\n",
      "        Neutrophil\n",
      "              2\n",
      "            Band Neutrophil\n",
      "            Segmented Neutrophil\n",
      " \n",
      "        Basophil\n",
      "        Eosinophil\n",
      "        Monocyte\n",
      " \n",
      " \n",
      "abnormal\n",
      "      6\n",
      "    Not Identifiable\n",
      "    Other Cell\n",
      "    Abnormal Eosinophil\n",
      "    Artefact\n",
      "    Smudge Cell\n",
      "    Faggott Cell\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "CELL_TYPES = {\n",
    "    'erythropoiesis': {\n",
    "        'Proerythroblast': 'PEB',\n",
    "        'Erythroblast': 'EBO',\n",
    "    },\n",
    "    'lymphoid': {\n",
    "        'Immature Lymphocyte': 'LYI',\n",
    "        'Lymphocyte': 'LYT',\n",
    "        'Plasma Cell': 'PLM',\n",
    "    },\n",
    "    'myeloid': {\n",
    "        'myeloid_immature': {\n",
    "            'Myeloblast': 'BLA',\n",
    "            'Metamyelocyte': 'MMZ',\n",
    "            'Myelocyte': 'MYB',\n",
    "            'Promyelocyte': 'PMO',\n",
    "        },\n",
    "        'myeloid_mature': {\n",
    "            'Neutrophil': {\n",
    "                'Band Neutrophil': 'NGB',\n",
    "                'Segmented Neutrophil': 'NGS',\n",
    "            },\n",
    "            'Basophil': 'BAS',\n",
    "            'Eosinophil': 'EOS',\n",
    "            'Monocyte': 'MON',\n",
    "        },\n",
    "    },\n",
    "    'abnormal': {\n",
    "        'Not Identifiable': 'NIF',\n",
    "        'Other Cell': 'OTH',\n",
    "        'Abnormal Eosinophil': 'ABE',\n",
    "        'Artefact': 'ART',\n",
    "        'Smudge Cell': 'KSC',\n",
    "        'Faggott Cell': 'FGC'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_number_of_classes(class_map: dict, depth: int = -1):\n",
    "    depth += 1\n",
    "    print(' ' * 4 * depth + ' ' * 2 + str(len(class_map.keys())))\n",
    "    for k, v in class_map.items():\n",
    "        print(' ' * 4 * depth + str(k))\n",
    "        if isinstance(v, dict):\n",
    "            get_number_of_classes(v, depth)\n",
    "    print(' ')\n",
    "\n",
    "get_number_of_classes(CELL_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed6763",
   "metadata": {},
   "source": [
    "# Extract from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18c35be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:44.199722Z",
     "start_time": "2022-01-10T00:00:44.193395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('datasets/BM_cytomorphology_data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = Path('./datasets/BM_cytomorphology_data/')\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bf8a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:44.951185Z",
     "start_time": "2022-01-10T00:00:44.202932Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE_TYPE = '.jpg'\n",
    "\n",
    "def extract_class_names(class_map: dict, class_names: dict = dict()):\n",
    "    for v in class_map.values():\n",
    "        if isinstance(v, dict):\n",
    "            class_names.update(extract_class_names(v, class_names))\n",
    "        else:\n",
    "            class_names[v] = set()\n",
    "    return class_names\n",
    "\n",
    "CLASS_PATHS = extract_class_names(CELL_TYPES)\n",
    "\n",
    "for TYPE in DATA_PATH.iterdir():\n",
    "    if CLASS_PATHS.get(TYPE.name, None) is not None:\n",
    "        for path in TYPE.resolve().iterdir():\n",
    "            if path.is_dir():\n",
    "                for image in path.iterdir():\n",
    "                    image_path = image.__str__()\n",
    "                    if IMAGE_FILE_TYPE in image_path:\n",
    "                        CLASS_PATHS[TYPE.name].add(image_path)\n",
    "            else:\n",
    "                image_path = path.__str__()\n",
    "                if IMAGE_FILE_TYPE in image_path:\n",
    "                    CLASS_PATHS[TYPE.name].add(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014edbae",
   "metadata": {},
   "source": [
    "# DataSet summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f95969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:45.232012Z",
     "start_time": "2022-01-10T00:00:44.953118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(list(CLASS_PATHS.keys()), [len(v) for v in CLASS_PATHS.values()], color='coral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c304d4b",
   "metadata": {},
   "source": [
    "# Balancing and Preparing: Train, Validation and Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4213acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T06:11:05.722903Z",
     "start_time": "2022-01-10T06:11:04.853091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] erythropoiesis 2740\n",
      "[0, 1] lymphoid 7629\n",
      "[0, 1, 2, 3] myeloid_immature 3055\n",
      "[0, 1] Neutrophil 9968\n",
      "[0, 1, 2] myeloid_mature 4040\n",
      "[0, 1] myeloid 12120\n",
      "[0, 1] abnormal 3538\n",
      "[0, 1, 2, 3] root 5480\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD_CLASS_SIZE = 1000\n",
    "TEST_RATIO = 0.1\n",
    "TRAIN_RATIO = 0.9\n",
    "DEPTH_MAX = 2\n",
    "\n",
    "def shuffle_dict(d):\n",
    "    l = list(d.items())\n",
    "    random.shuffle(l)\n",
    "    return dict(l)\n",
    "\n",
    "def slice_dict(d: dict, end: int, start: int = 0):\n",
    "    keys = list(d.keys())\n",
    "    if end == -1:\n",
    "        end = len(keys)\n",
    "    return {k: d[k] for k in keys[start:end]}\n",
    "\n",
    "def prepare_nested_samples(class_map: dict, parent_name: str = 'root', depth: int = 0):\n",
    "    result = {parent_name: {\n",
    "        'train': dict(),\n",
    "        'validation': dict(),\n",
    "        'test': dict(),\n",
    "    }}\n",
    "    \n",
    "    all_samples = dict()\n",
    "    MIN_SIZE = None\n",
    "    LABEL = 0\n",
    "    label_map = dict()\n",
    "\n",
    "    def pre_min_balancing(paths: dict, min_size: int) -> dict():\n",
    "        if len(paths) >= THRESHOLD_CLASS_SIZE:\n",
    "            if min_size is None or len(paths) < min_size:\n",
    "                min_size = len(paths)\n",
    "            paths = shuffle_dict(paths)\n",
    "            p_balanced = slice_dict(paths, min_size)\n",
    "            return p_balanced, min_size\n",
    "        return dict(), min_size\n",
    "\n",
    "    \n",
    "    for k, v in class_map.items():\n",
    "        if isinstance(v, dict):\n",
    "            sub_result = prepare_nested_samples(\n",
    "                class_map=v,\n",
    "                parent_name=k,\n",
    "                depth=depth+1\n",
    "            )\n",
    "            all_p = {p: LABEL for p in sub_result[k]['all']}\n",
    "            labeled_paths, MIN_SIZE = pre_min_balancing(all_p, MIN_SIZE)\n",
    "            if labeled_paths:\n",
    "                all_samples[LABEL] = labeled_paths\n",
    "                label_map[LABEL] = k\n",
    "                result.update(sub_result)\n",
    "                LABEL += 1\n",
    "        else:\n",
    "            paths = {p: LABEL for p in CLASS_PATHS[v]}\n",
    "            labeled_paths, MIN_SIZE = pre_min_balancing(paths, MIN_SIZE)\n",
    "            if labeled_paths:\n",
    "                all_samples[LABEL] = labeled_paths\n",
    "                label_map[LABEL] = k\n",
    "                LABEL += 1\n",
    "\n",
    "    # Slice samples.\n",
    "    all_balanced = dict()\n",
    "    print(list(label_map.keys()), parent_name, MIN_SIZE)\n",
    "    for label, paths in all_samples.items():\n",
    "        # Shuffle and slice.\n",
    "        part = shuffle_dict(slice_dict(shuffle_dict(paths), MIN_SIZE))\n",
    "\n",
    "        # Calculate sizes.\n",
    "        test_size = int(len(part) * TEST_RATIO)\n",
    "        train_size = int((len(part) - test_size) * TRAIN_RATIO)\n",
    "\n",
    "        # Assign samples categories.\n",
    "        train = slice_dict(part, train_size)\n",
    "        validation = slice_dict(part, -test_size, train_size)\n",
    "        test = slice_dict(part, -1, -test_size)\n",
    "        result[parent_name]['train'].update(train)\n",
    "        result[parent_name]['validation'].update(validation)\n",
    "        result[parent_name]['test'].update(test)\n",
    "\n",
    "        # Grab all.\n",
    "        all_balanced.update(train)\n",
    "        all_balanced.update(validation)\n",
    "        all_balanced.update(test)\n",
    "    \n",
    "    # Additional info.\n",
    "    result[parent_name]['label_map'] = label_map\n",
    "    result[parent_name]['all'] = all_balanced\n",
    "    result[parent_name]['class_number'] = MIN_SIZE\n",
    "    result[parent_name]['depth'] = depth\n",
    "    \n",
    "    return result\n",
    "\n",
    "PREPARED = prepare_nested_samples(CELL_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b83ca8",
   "metadata": {},
   "source": [
    "# Full dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d05f6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:45.988901Z",
     "start_time": "2022-01-10T00:00:45.982255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation pipeline\n",
    "TRANSFORM = A.Compose([\n",
    "    A.Rotate(p=0.8),\n",
    "    A.RandomBrightnessContrast(p=0.6),\n",
    "    A.RandomGamma(),\n",
    "    A.Blur(p=0.2),\n",
    "    A.Sharpen(),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c89674e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:46.002140Z",
     "start_time": "2022-01-10T00:00:45.992237Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_W = 256\n",
    "IMG_H = 256\n",
    "DIMENSION = (IMG_W, IMG_H)\n",
    "\n",
    "class ModifiedDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get by index.\n",
    "        image_path = list(self.paths.keys())[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize for unified size.\n",
    "        image = cv2.resize(image, DIMENSION)\n",
    "        \n",
    "        # Convert to working color space.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Normilize image.\n",
    "        image = np.float32(image/255)\n",
    "\n",
    "        # Get image label\n",
    "        label = self.paths[image_path]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e3d11b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:46.024040Z",
     "start_time": "2022-01-10T00:00:46.007686Z"
    }
   },
   "outputs": [],
   "source": [
    "# DON'T DELETE!!!!!\n",
    "# def visualize_augmentations(dataset, label_map, idx=0, samples=10, cols=5):\n",
    "#     dataset = copy.deepcopy(dataset)\n",
    "#     dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "#     rows = samples // cols\n",
    "#     figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 5))\n",
    "#     for i in range(samples):\n",
    "#         image, label = dataset[idx]\n",
    "#         ax.ravel()[i].imshow(image)\n",
    "#         ax.ravel()[i].set_axis_off()\n",
    "#     print('CLASS NAME: ', label_map[label])\n",
    "#     plt.show()\n",
    "\n",
    "# visualize_augmentations(\n",
    "#     train_dataset,\n",
    "#     DATASET['label_map'],\n",
    "#     random.randint(0, len(DATASET['train']))\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb9f1d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f9f155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:46.037061Z",
     "start_time": "2022-01-10T00:00:46.026612Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa14d2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:46.049681Z",
     "start_time": "2022-01-10T00:00:46.039396Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    stream = tqdm(train_loader)\n",
    "    for i, (train_images, target) in enumerate(stream, start=1):\n",
    "        # BATCH PREPARATION\n",
    "        X = train_images.to(DEVICE, non_blocking=True)\n",
    "        y = target.to(DEVICE, non_blocking=True).long()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        y_preds = model(X)\n",
    "        loss = criterion(y_preds, y)\n",
    "        if i == len(train_loader):\n",
    "            loss_save = loss.item()\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Output\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch+1, metric_monitor=metric_monitor)\n",
    "        )\n",
    "        \n",
    "    return loss_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da82f1cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:46.065043Z",
     "start_time": "2022-01-10T00:00:46.051997Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (validation_images, target) in enumerate(stream, start=1):\n",
    "            X = validation_images.to(DEVICE, non_blocking=True)\n",
    "            y = target.to(DEVICE, non_blocking=True).long()\n",
    "            y_preds = model(X)\n",
    "            \n",
    "            # LOSS\n",
    "            loss = criterion(y_preds, y)\n",
    "            if i == len(val_loader):\n",
    "                loss_save = loss.item()\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation.    {metric_monitor}\".format(epoch=epoch+1, metric_monitor=metric_monitor)\n",
    "            )\n",
    "    return loss_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f348fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T00:00:46.139141Z",
     "start_time": "2022-01-10T00:00:46.067538Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "def inference(dataset, case_name: str = ''):\n",
    "    modes = {\n",
    "        'clean': {\n",
    "            'pretrained': False,\n",
    "            'transform': False,\n",
    "        },\n",
    "        'pretrained': {\n",
    "            'pretrained': True,\n",
    "            'transform': False,\n",
    "        },\n",
    "        'pretrained_augmentated': {\n",
    "            'pretrained': True,\n",
    "            'transform': True,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    NUM_CLASSES = len(dataset['label_map'])\n",
    "    \n",
    "    accuracy_summary = dict()\n",
    "    \n",
    "    if case_name != '':\n",
    "        case_name = '_' + case_name\n",
    "    \n",
    "    for m in modes:\n",
    "        pretrained = modes[m]['pretrained']\n",
    "        ALL_MODELS = {\n",
    "            'mobilenet': models.mobilenet_v3_large(pretrained=pretrained),\n",
    "            'resnet': models.resnet34(pretrained=pretrained),\n",
    "            'efficientnet': models.efficientnet_b2(pretrained=pretrained),\n",
    "            'regnet': models.regnet_y_800mf(pretrained=pretrained),\n",
    "        }\n",
    "        # TODO(dmtgk): Now system works only with ResNet model.\n",
    "        SELECTED = 'resnet'\n",
    "        MODEL = ALL_MODELS[SELECTED]\n",
    "    \n",
    "        # Change last layer if pretrained mode.\n",
    "        if pretrained:\n",
    "            if SELECTED == 'mobilenet':\n",
    "                arch = 'mobilenet_v3_large'\n",
    "                inverted_residual_setting, last_channel = models.mobilenetv3._mobilenet_v3_conf(arch)\n",
    "                MODEL.classifier[3] = nn.Linear(last_channel, NUM_CLASSES)\n",
    "            elif SELECTED == 'resnet' or SELECTED == 'regnet':\n",
    "                MODEL.fc = torch.nn.Linear(MODEL.fc.in_features, NUM_CLASSES)\n",
    "            elif SELECTED == 'efficientnet':\n",
    "                inverted_residual_setting = models.efficientnet._efficientnet_conf(width_mult=1.1, depth_mult=1.2)\n",
    "                lastconv_input_channels = inverted_residual_setting[-1].out_channels\n",
    "                lastconv_output_channels = 4 * lastconv_input_channels\n",
    "                MODEL.classifier[1] = nn.Linear(lastconv_output_channels, NUM_CLASSES)\n",
    "        MODEL.to(DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "        optimizer = optim.Adam(MODEL.parameters(), lr=0.0001)\n",
    "        \n",
    "        transform_selected = A.Compose([ToTensorV2()])\n",
    "        if modes[m]['transform']:\n",
    "            transform_selected = TRANSFORM\n",
    "    \n",
    "        train_dataset = ModifiedDataset(\n",
    "            paths=dataset['train'],\n",
    "            transform=transform_selected\n",
    "        )\n",
    "        val_dataset = ModifiedDataset(\n",
    "            paths=dataset['validation'],\n",
    "            transform=transform_selected\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        train_all_losses = list()\n",
    "        val_all_losses = list()\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss = train(train_loader, MODEL, criterion, optimizer, epoch)\n",
    "            train_all_losses.append(train_loss)\n",
    "\n",
    "            val_loss = validate(val_loader, MODEL, criterion, epoch)\n",
    "            val_all_losses.append(val_loss)\n",
    "\n",
    "        # Loss rate by epoch.\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.plot(train_all_losses, label=\"Train Loss\")\n",
    "        ax.plot(val_all_losses, label=\"Validation Loss\")\n",
    "        ax.legend()\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss rate')\n",
    "        plt.savefig(os.path.join('results', SELECTED + '_' + m + case_name + '.png'))\n",
    "        \n",
    "        # Test.\n",
    "        test_transform = A.Compose([ToTensorV2()])\n",
    "        test_dataset = ModifiedDataset(\n",
    "            paths=dataset['test'],\n",
    "            transform=test_transform\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        # Evaluate Test Data.\n",
    "        model = MODEL.eval()\n",
    "        correct = {label: 0 for label in dataset['label_map'].keys()}\n",
    "        total = {label: 0 for label in dataset['label_map'].keys()}\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                test_images, labels = data\n",
    "                test_images = test_images.to(DEVICE, non_blocking=True)\n",
    "                labels = labels.to(DEVICE, non_blocking=True).long()\n",
    "                outputs = model(test_images)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                # Count correct predictions for the each class.\n",
    "                for label, prediction in zip(labels, predictions):\n",
    "                    if label == prediction:\n",
    "                        correct[label.item()] += 1\n",
    "                    total[label.item()] += 1\n",
    "        correct_summary = {dataset['label_map'][k]: v for k, v in correct.items()}\n",
    "        total_summary = {dataset['label_map'][k]: v for k, v in total.items()}\n",
    "        \n",
    "        # Get accuracy for each class.\n",
    "        accs = list()\n",
    "        for classname, correct_count in correct_summary.items():\n",
    "            predicted_count = total_summary[classname]\n",
    "            if predicted_count == 0:\n",
    "                predicted_count = 1\n",
    "            accuracy = 100 * float(correct_count) / predicted_count\n",
    "            accs.append(accuracy)\n",
    "#             print(\"{:5s} {:.1f} %\".format(classname, accuracy))\n",
    "#         print(f\"Total accuracy on all classes is {round(np.mean(accs), 2)} %\")\n",
    "        accuracy_summary[m] = np.mean(accs)\n",
    "        \n",
    "        # Free resources space.\n",
    "        del MODEL\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return accuracy_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9ee84",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-10T00:00:41.250Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 1.150: 100%|██████████| 555/555 [01:04<00:00,  8.56it/s]\n",
      "Epoch: 1. Validation.    Loss: 0.816: 100%|██████████| 62/62 [00:03<00:00, 18.54it/s]\n",
      "Epoch: 2. Train.      Loss: 0.704: 100%|██████████| 555/555 [01:04<00:00,  8.59it/s]\n",
      "Epoch: 2. Validation.    Loss: 1.037: 100%|██████████| 62/62 [00:03<00:00, 18.28it/s]\n",
      "Epoch: 3. Train.      Loss: 0.589: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 3. Validation.    Loss: 0.586: 100%|██████████| 62/62 [00:03<00:00, 17.86it/s]\n",
      "Epoch: 4. Train.      Loss: 0.526: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 4. Validation.    Loss: 0.612: 100%|██████████| 62/62 [00:03<00:00, 18.63it/s]\n",
      "Epoch: 5. Train.      Loss: 0.468: 100%|██████████| 555/555 [01:04<00:00,  8.62it/s]\n",
      "Epoch: 5. Validation.    Loss: 0.584: 100%|██████████| 62/62 [00:03<00:00, 17.93it/s]\n",
      "Epoch: 6. Train.      Loss: 0.421: 100%|██████████| 555/555 [01:04<00:00,  8.59it/s]\n",
      "Epoch: 6. Validation.    Loss: 0.707: 100%|██████████| 62/62 [00:03<00:00, 17.30it/s]\n",
      "Epoch: 7. Train.      Loss: 0.375: 100%|██████████| 555/555 [01:04<00:00,  8.63it/s]\n",
      "Epoch: 7. Validation.    Loss: 0.482: 100%|██████████| 62/62 [00:03<00:00, 18.47it/s]\n",
      "Epoch: 8. Train.      Loss: 0.324: 100%|██████████| 555/555 [01:04<00:00,  8.64it/s]\n",
      "Epoch: 8. Validation.    Loss: 0.631: 100%|██████████| 62/62 [00:03<00:00, 17.71it/s]\n",
      "Epoch: 9. Train.      Loss: 0.270: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 9. Validation.    Loss: 0.621: 100%|██████████| 62/62 [00:03<00:00, 17.48it/s]\n",
      "Epoch: 10. Train.      Loss: 0.216: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 10. Validation.    Loss: 0.596: 100%|██████████| 62/62 [00:03<00:00, 17.69it/s]\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-bcdf34b7.pth\" to /home/aparfenenkova/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-bcdf34b7.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c13af915ff4a8d89156fcf2e9bb938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36882185), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/regnet_y_800mf-1b27b58c.pth\" to /home/aparfenenkova/.cache/torch/hub/checkpoints/regnet_y_800mf-1b27b58c.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa774b1d4af49c3a6bfb2f9c49fce60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25977049), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 0.497: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 1. Validation.    Loss: 0.354: 100%|██████████| 62/62 [00:03<00:00, 18.15it/s]\n",
      "Epoch: 2. Train.      Loss: 0.309: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 2. Validation.    Loss: 0.367: 100%|██████████| 62/62 [00:03<00:00, 18.18it/s]\n",
      "Epoch: 3. Train.      Loss: 0.214: 100%|██████████| 555/555 [01:04<00:00,  8.58it/s]\n",
      "Epoch: 3. Validation.    Loss: 0.346: 100%|██████████| 62/62 [00:03<00:00, 18.09it/s]\n",
      "Epoch: 4. Train.      Loss: 0.140: 100%|██████████| 555/555 [01:04<00:00,  8.57it/s]\n",
      "Epoch: 4. Validation.    Loss: 0.454: 100%|██████████| 62/62 [00:03<00:00, 18.42it/s]\n",
      "Epoch: 5. Train.      Loss: 0.113: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 5. Validation.    Loss: 0.454: 100%|██████████| 62/62 [00:03<00:00, 18.39it/s]\n",
      "Epoch: 6. Train.      Loss: 0.078: 100%|██████████| 555/555 [01:04<00:00,  8.62it/s]\n",
      "Epoch: 6. Validation.    Loss: 0.511: 100%|██████████| 62/62 [00:03<00:00, 18.29it/s]\n",
      "Epoch: 7. Train.      Loss: 0.061: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 7. Validation.    Loss: 0.482: 100%|██████████| 62/62 [00:03<00:00, 17.99it/s]\n",
      "Epoch: 8. Train.      Loss: 0.057: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 8. Validation.    Loss: 0.517: 100%|██████████| 62/62 [00:03<00:00, 18.66it/s]\n",
      "Epoch: 9. Train.      Loss: 0.058: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 9. Validation.    Loss: 0.492: 100%|██████████| 62/62 [00:03<00:00, 18.59it/s]\n",
      "Epoch: 10. Train.      Loss: 0.036: 100%|██████████| 555/555 [01:04<00:00,  8.63it/s]\n",
      "Epoch: 10. Validation.    Loss: 0.525: 100%|██████████| 62/62 [00:03<00:00, 18.48it/s]\n",
      "Epoch: 1. Train.      Loss: 0.548: 100%|██████████| 555/555 [01:04<00:00,  8.62it/s]\n",
      "Epoch: 1. Validation.    Loss: 0.428: 100%|██████████| 62/62 [00:03<00:00, 16.90it/s]\n",
      "Epoch: 2. Train.      Loss: 0.403: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 2. Validation.    Loss: 0.387: 100%|██████████| 62/62 [00:03<00:00, 17.15it/s]\n",
      "Epoch: 3. Train.      Loss: 0.358: 100%|██████████| 555/555 [01:04<00:00,  8.59it/s]\n",
      "Epoch: 3. Validation.    Loss: 0.337: 100%|██████████| 62/62 [00:03<00:00, 17.02it/s]\n",
      "Epoch: 4. Train.      Loss: 0.329: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 4. Validation.    Loss: 0.368: 100%|██████████| 62/62 [00:03<00:00, 16.51it/s]\n",
      "Epoch: 5. Train.      Loss: 0.308: 100%|██████████| 555/555 [01:04<00:00,  8.58it/s]\n",
      "Epoch: 5. Validation.    Loss: 0.341: 100%|██████████| 62/62 [00:03<00:00, 17.16it/s]\n",
      "Epoch: 6. Train.      Loss: 0.287: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 6. Validation.    Loss: 0.357: 100%|██████████| 62/62 [00:03<00:00, 17.23it/s]\n",
      "Epoch: 7. Train.      Loss: 0.268: 100%|██████████| 555/555 [01:04<00:00,  8.56it/s]\n",
      "Epoch: 7. Validation.    Loss: 0.347: 100%|██████████| 62/62 [00:03<00:00, 16.39it/s]\n",
      "Epoch: 8. Train.      Loss: 0.260: 100%|██████████| 555/555 [01:04<00:00,  8.58it/s]\n",
      "Epoch: 8. Validation.    Loss: 0.303: 100%|██████████| 62/62 [00:03<00:00, 16.76it/s]\n",
      "Epoch: 9. Train.      Loss: 0.240: 100%|██████████| 555/555 [01:04<00:00,  8.60it/s]\n",
      "Epoch: 9. Validation.    Loss: 0.344: 100%|██████████| 62/62 [00:03<00:00, 17.01it/s]\n",
      "Epoch: 10. Train.      Loss: 0.226: 100%|██████████| 555/555 [01:04<00:00,  8.61it/s]\n",
      "Epoch: 10. Validation.    Loss: 0.340: 100%|██████████| 62/62 [00:03<00:00, 16.49it/s]\n",
      "Epoch: 1. Train.      Loss: 0.703: 100%|██████████| 139/139 [00:16<00:00,  8.20it/s]\n",
      "Epoch: 1. Validation.    Loss: 0.306: 100%|██████████| 16/16 [00:01<00:00,  9.02it/s]\n",
      "Epoch: 2. Train.      Loss: 0.207: 100%|██████████| 139/139 [00:16<00:00,  8.24it/s]\n",
      "Epoch: 2. Validation.    Loss: 0.241: 100%|██████████| 16/16 [00:01<00:00,  9.81it/s]\n",
      "Epoch: 3. Train.      Loss: 0.170: 100%|██████████| 139/139 [00:16<00:00,  8.23it/s]\n",
      "Epoch: 3. Validation.    Loss: 0.165: 100%|██████████| 16/16 [00:01<00:00,  9.52it/s]\n",
      "Epoch: 4. Train.      Loss: 0.148: 100%|██████████| 139/139 [00:17<00:00,  8.12it/s]\n",
      "Epoch: 4. Validation.    Loss: 0.169: 100%|██████████| 16/16 [00:01<00:00,  9.48it/s]\n",
      "Epoch: 5. Train.      Loss: 0.137: 100%|██████████| 139/139 [00:16<00:00,  8.30it/s]\n",
      "Epoch: 5. Validation.    Loss: 0.198: 100%|██████████| 16/16 [00:01<00:00,  9.67it/s]\n",
      "Epoch: 6. Train.      Loss: 0.126: 100%|██████████| 139/139 [00:16<00:00,  8.22it/s]\n",
      "Epoch: 6. Validation.    Loss: 0.159: 100%|██████████| 16/16 [00:01<00:00,  9.85it/s]\n",
      "Epoch: 7. Train.      Loss: 0.113: 100%|██████████| 139/139 [00:16<00:00,  8.21it/s]\n",
      "Epoch: 7. Validation.    Loss: 0.164: 100%|██████████| 16/16 [00:01<00:00,  9.64it/s]\n",
      "Epoch: 8. Train.      Loss: 0.106: 100%|██████████| 139/139 [00:16<00:00,  8.23it/s]\n",
      "Epoch: 8. Validation.    Loss: 0.197: 100%|██████████| 16/16 [00:01<00:00,  9.37it/s]\n",
      "Epoch: 9. Train.      Loss: 0.097: 100%|██████████| 139/139 [00:16<00:00,  8.24it/s]\n",
      "Epoch: 9. Validation.    Loss: 0.215: 100%|██████████| 16/16 [00:01<00:00,  9.89it/s]\n",
      "Epoch: 10. Train.      Loss: 0.094: 100%|██████████| 139/139 [00:16<00:00,  8.21it/s]\n",
      "Epoch: 10. Validation.    Loss: 0.301: 100%|██████████| 16/16 [00:01<00:00, 10.44it/s]\n",
      "Epoch: 1. Train.      Loss: 0.162: 100%|██████████| 139/139 [00:16<00:00,  8.18it/s]\n",
      "Epoch: 1. Validation.    Loss: 0.115: 100%|██████████| 16/16 [00:01<00:00, 10.24it/s]\n",
      "Epoch: 2. Train.      Loss: 0.062:  81%|████████  | 112/139 [00:13<00:03,  8.81it/s]"
     ]
    }
   ],
   "source": [
    "summary_table = pd.DataFrame()\n",
    "\n",
    "for case in PREPARED.keys():\n",
    "    mean_acc = inference(PREPARED[case], case)\n",
    "    mean_acc.update({'case': case})\n",
    "    summary_table = summary_table.append(pd.DataFrame([mean_acc]))\n",
    "\n",
    "summary_table = summary_table.append(pd.DataFrame([{\n",
    "    'clean': np.mean(summary_table['clean']),\n",
    "    'pretrained': np.mean(summary_table['pretrained']),\n",
    "    'pretrained_augmentated': np.mean(summary_table['pretrained_augmentated']),\n",
    "    'case': 'all',\n",
    "}]))\n",
    "\n",
    "summary_table.to_csv('summary.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250536e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
